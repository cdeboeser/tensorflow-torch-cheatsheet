{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf.data Dataset for Neural Machine Translation from json-lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import json\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebooks shows a simple example how to use the tf.data API to write an input pipeline from a json-lines file for model training. \n",
    "\n",
    "> Note: For simplicity, this notebook uses a functional programming style. It often makes sense to use a object-oriented style instead.\n",
    "\n",
    "The dataset containts English-German language tuples. Each line in the data looks like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"src\": [\n",
      "        \"Two\",\n",
      "        \"young\",\n",
      "        \",\",\n",
      "        \"White\",\n",
      "        \"males\",\n",
      "        \"are\",\n",
      "        \"outside\",\n",
      "        \"near\",\n",
      "        \"many\",\n",
      "        \"bushes\",\n",
      "        \".\"\n",
      "    ],\n",
      "    \"tgt\": [\n",
      "        \"Zwei\",\n",
      "        \"junge\",\n",
      "        \"wei\\u00dfe\",\n",
      "        \"M\\u00e4nner\",\n",
      "        \"sind\",\n",
      "        \"im\",\n",
      "        \"Freien\",\n",
      "        \"in\",\n",
      "        \"der\",\n",
      "        \"N\\u00e4he\",\n",
      "        \"vieler\",\n",
      "        \"B\\u00fcsche\",\n",
      "        \".\"\n",
      "    ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_file = 'data/jsonl/data_train.jsonl'\n",
    "\n",
    "with open(data_file) as f:\n",
    "    line = next(f)\n",
    "    print(json.dumps(json.loads(line), indent=4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Stoi (string-to-integer) vocabs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Native python dicts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first create the lookup-tables to map from words to integers. This should be done ahead of training and stored to a file to not slow down the preparation of the dataset, especially for larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most common tokens in source (English):\n",
      "['a', '.', 'A', 'in', 'the']\n",
      "Most common tokens in target (German):\n",
      "['.', 'Ein', ',', 'einem', 'mit']\n"
     ]
    }
   ],
   "source": [
    "src_vocab = Counter()\n",
    "tgt_vocab = Counter()\n",
    "\n",
    "with open(data_file, 'r') as f:\n",
    "    for line in f:\n",
    "        obj = json.loads(line)\n",
    "        src_vocab += Counter(obj['src'])\n",
    "        tgt_vocab += Counter(obj['tgt'])\n",
    "\n",
    "print(\"Most common tokens in source (English):\")\n",
    "print([w for w, _ in src_vocab.most_common(5)])\n",
    "\n",
    "print(\"Most common tokens in target (German):\")\n",
    "print([w for w, _ in tgt_vocab.most_common(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the best practives for language datasets, we use paddings, a token for unknowns, as well as start and end of sequence tokens. Note that we only start enumerating the vocabs at 4 since with use:\n",
    "\n",
    "    <PAD> = 0  # Padding index\n",
    "    <UNK> = 1  # Index for unknown tokens\n",
    "    <SOS> = 2  # Start of sequence index\n",
    "    <EOS> = 3  # End of sequence index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 87)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src_vocab_stoi = {word: c for c, (word, _) in enumerate(src_vocab.most_common(len(src_vocab)), 4)}\n",
    "tgt_vocab_stoi = {word: c for c, (word, _) in enumerate(tgt_vocab.most_common(len(tgt_vocab)), 4)}\n",
    "\n",
    "src_vocab_stoi['one'], tgt_vocab_stoi['Nähe']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the src vocab: 4,921\n",
      "Length of the tgt vocab: 6,818\n"
     ]
    }
   ],
   "source": [
    "print(\"Length of the src vocab: {:,}\\nLength of the tgt vocab: {:,}\".format(len(src_vocab_stoi), len(tgt_vocab_stoi)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tensorflow lookups"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use Tensorflow's `StaticHashTable` to create a tensor-style lookup table. It is basically a dict for tensorflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tf_vocab_from_dict(vocab, oov_index=1):\n",
    "    return tf.lookup.StaticHashTable(\n",
    "                initializer=tf.lookup.KeyValueTensorInitializer(\n",
    "                    keys=tf.constant(list(vocab.keys())),\n",
    "                    values=tf.constant(list(vocab.values()))),\n",
    "                default_value=tf.constant(oov_index))\n",
    "\n",
    "tf_src_vocab_stoi = tf_vocab_from_dict(src_vocab_stoi)\n",
    "tf_tgt_vocab_stoi = tf_vocab_from_dict(tgt_vocab_stoi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([66, 77], dtype=int32)>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_src_vocab_stoi.lookup(tf.constant(['one', 'two']))  # One is index 66, two is index 77"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(2,), dtype=int32, numpy=array([87,  1], dtype=int32)>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_tgt_vocab_stoi.lookup(tf.constant(['Nähe', 'Distanz']))  # Nähe is index 87, Distanz is not in Vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step-by-step: Creating the tf.data.Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading from the json-lines format, we have to first read and decode the data before feeding it into tf.data. The generator-function below reads the data-file and yields a `(source string, target string)` tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def json_generator(file_name):\n",
    "    with open(file_name, 'r') as f:\n",
    "        for line in f:\n",
    "            obj = json.loads(line)\n",
    "            yield \" \".join(obj['src']), \" \".join(obj['tgt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen = json_generator(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Two young , White males are outside near many bushes .',\n",
       " 'Zwei junge weiße Männer sind im Freien in der Nähe vieler Büsche .')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(gen))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1: Reading from Generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_1 = tf.data.Dataset.from_generator(\n",
    "    lambda: map(tuple, json_generator(data_file)), \n",
    "    output_types=(tf.string, tf.string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=string, numpy=b'Two young , White males are outside near many bushes .'>,\n",
       " <tf.Tensor: shape=(), dtype=string, numpy=b'Zwei junge wei\\xc3\\x9fe M\\xc3\\xa4nner sind im Freien in der N\\xc3\\xa4he vieler B\\xc3\\xbcsche .'>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Preprocessing the strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_stoi = tf_src_vocab_stoi\n",
    "tgt_stoi = tf_tgt_vocab_stoi\n",
    "sos_index = tf.constant([2])\n",
    "eos_index = tf.constant([3])\n",
    "\n",
    "def preprocess_function(src, tgt):\n",
    "    # Breaking string into tokens\n",
    "    src = tf.strings.split(tf.expand_dims(src, axis=0), sep=' ')[0]\n",
    "    tgt = tf.strings.split(tf.expand_dims(tgt, axis=0), sep=' ')[0]\n",
    "    \n",
    "    # Converting strings to ints\n",
    "    src = src_stoi.lookup(src)\n",
    "    tgt = tgt_stoi.lookup(tgt)\n",
    "    \n",
    "    # Adding SOS and EOS\n",
    "    src = tf.concat([sos_index, src, eos_index], axis=0)\n",
    "    tgt = tf.concat([sos_index, tgt, eos_index], axis=0)\n",
    "    \n",
    "    # Length of the src sequence\n",
    "    src_len = tf.expand_dims(tf.shape(src)[0], axis=0)\n",
    "    tgt_len = tf.expand_dims(tf.shape(tgt)[0], axis=0)\n",
    "\n",
    "    return src, tgt, src_len, tgt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_2 = dataset_1.map(preprocess_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(13,), dtype=int32, numpy=\n",
       " array([   2,   18,   27,   15,  833,  699,   16,   58,   78,  389, 1042,\n",
       "           5,    3], dtype=int32)>,\n",
       " <tf.Tensor: shape=(15,), dtype=int32, numpy=\n",
       " array([   2,   22,  118,  201,   35,  100,   21,   86,    9,   14,   87,\n",
       "        1841, 2729,    4,    3], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([13], dtype=int32)>,\n",
       " <tf.Tensor: shape=(1,), dtype=int32, numpy=array([15], dtype=int32)>)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Batching and Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_3 = dataset_2.padded_batch(batch_size, padded_shapes=([None], [None], [1], [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 17), dtype=int32, numpy=\n",
       " array([[   2,   18,   27,   15,  833,  699,   16,   58,   78,  389, 1042,\n",
       "            5,    3,    0,    0,    0,    0],\n",
       "        [   2,  184,   38,    7,  307,  298,   16,  760,    4,  761, 1465,\n",
       "         1863,    5,    3,    0,    0,    0],\n",
       "        [   2,    6,   52,   30,  172,   61,    4,  198, 2575,    5,    3,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,    7,    4,   36,   25,   11,   35,    9,    4,\n",
       "          526,  605,    4,  199,    5,    3]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 17), dtype=int32, numpy=\n",
       " array([[   2,   22,  118,  201,   35,  100,   21,   86,    9,   14,   87,\n",
       "         1841, 2729,    4,    3,    0,    0],\n",
       "        [   2,  107,   35,    8,  651, 1141,   16, 2730,    4,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   72,   26,  174,    9,   16, 2731,   55,  395,    4,\n",
       "            3,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   12,    9,    7,   65,   36,   30,   11,   13,  506,\n",
       "           10,  652,   16,  202,    4,    3]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       " array([[13],\n",
       "        [14],\n",
       "        [11],\n",
       "        [17]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       " array([[15],\n",
       "        [10],\n",
       "        [12],\n",
       "        [17]], dtype=int32)>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Putting it all together"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "                lambda: map(tuple, json_generator(data_file)), \n",
    "                output_types=(tf.string,)*2)\\\n",
    "            .map(preprocess_function)\\\n",
    "            .padded_batch(batch_size, padded_shapes=([None], [None], [1], [1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(16, 19), dtype=int32, numpy=\n",
       " array([[   2,   18,   27,   15,  833,  699,   16,   58,   78,  389, 1042,\n",
       "            5,    3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,  184,   38,    7,  307,  298,   16,  760,    4,  761, 1465,\n",
       "         1863,    5,    3,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   52,   30,  172,   61,    4,  198, 2575,    5,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,    7,    4,   36,   25,   11,   35,    9,    4,\n",
       "          526,  605,    4,  199,    5,    3,    0,    0],\n",
       "        [   2,   18,   38,   16,   20,    8,  762,  324,  132,    5,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,    7,   53,  135,    4,  105,   29,    8,   90,\n",
       "           10, 1466,   33,   25,    5,    3,    0,    0],\n",
       "        [   2,    6,   10,   11,  126,   20,    4,  763, 1864,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6, 2576,   30,  106,    9,   49,  368,   29, 2577, 1865,\n",
       "           39,    8,   47,    5,    3,    0,    0,    0],\n",
       "        [   2,    6,   17,   14,    4,   55,  606,   11,   44,   51,    4,\n",
       "          764,    5,    3,    0,    0,    0,    0,    0],\n",
       "        [   2, 1226,  380,    9,  834,    7,    8,  221,   13,    8,  390,\n",
       "            5,    3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6, 2578,  700,   13,  646,   98,   87,    7, 1866,    5,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,  146,  391,  204,   21,  298,   66, 1467,   16,   87,   20,\n",
       "            8,  109,   13,    4,  921,    5,    3,    0],\n",
       "        [   2,    6,   26,   22,   12,    4, 1468,   22,   16,  647,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,    7,    4, 1043,   53,   12,  103,  308,   11,\n",
       "          392,    9,    4,   53,  572,    5,    3,    0],\n",
       "        [   2,  184,   60,  835,   58,    7,    4,  147,    5,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,  130,    7,    4,   26,  109,   14,  127,   11, 2579,\n",
       "         2580, 2581,    9,    4, 2582,  393,    5,    3]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(16, 20), dtype=int32, numpy=\n",
       " array([[   2,   22,  118,  201,   35,  100,   21,   86,    9,   14,   87,\n",
       "         1841, 2729,    4,    3,    0,    0,    0,    0,    0],\n",
       "        [   2,  107,   35,    8,  651, 1141,   16, 2730,    4,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   72,   26,  174,    9,   16, 2731,   55,  395,    4,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   12,    9,    7,   65,   36,   30,   11,   13,  506,\n",
       "           10,  652,   16,  202,    4,    3,    0,    0,    0],\n",
       "        [   2,   22,   35,   59,   44,  879,   10,  338,  195,   28,    4,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   12,    9,  364,   40,   18,  113,    6,   41,   14,\n",
       "          115,   12,  154,   36,  983,    4,    3,    0,    0],\n",
       "        [   2,    5,   12,  155,   19, 1842, 2732,   23,    4,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5, 2733,   26,  138,    8,   27,  311,   41,  135, 1843,\n",
       "           17,   43, 2734,    4,    3,    0,    0,    0,    0],\n",
       "        [   2,   15,   20,    8,   13,   79, 2735,   62,   23,    7,  653,\n",
       "          125,    4,    3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   83,  449,  320,    9,   14,  880,   11,  546,    4,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   15, 2736,    8,  984,   26,    6,   17, 1407,  257,    4,\n",
       "            3,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,  141, 1142,    6,   32,  365,  211, 1408,  188,   10,   13,\n",
       "          595,    6,  257,  328,    9,    7, 2737,    4,    3],\n",
       "        [   2,    5,   85,   25,   10,   16, 1844,   25,  353,    4,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   12,    9,   13, 2738,   10,  158,  710,   76,   11,\n",
       "            7,   94,  783,    4,    3,    0,    0,    0,    0],\n",
       "        [   2,  107,   64,  270,    9,   13,  181,   21,   86,    4,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   15,   20,    8,  126,   91,   10,  127, 1845, 2739,   11,\n",
       "            7, 2740,    4,    3,    0,    0,    0,    0,    0]],\n",
       "       dtype=int32)>,\n",
       " <tf.Tensor: shape=(16, 1), dtype=int32, numpy=\n",
       " array([[13],\n",
       "        [14],\n",
       "        [11],\n",
       "        [17],\n",
       "        [11],\n",
       "        [17],\n",
       "        [10],\n",
       "        [16],\n",
       "        [14],\n",
       "        [13],\n",
       "        [12],\n",
       "        [18],\n",
       "        [11],\n",
       "        [18],\n",
       "        [10],\n",
       "        [19]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(16, 1), dtype=int32, numpy=\n",
       " array([[15],\n",
       "        [10],\n",
       "        [12],\n",
       "        [17],\n",
       "        [12],\n",
       "        [18],\n",
       "        [10],\n",
       "        [16],\n",
       "        [14],\n",
       "        [11],\n",
       "        [12],\n",
       "        [20],\n",
       "        [11],\n",
       "        [16],\n",
       "        [11],\n",
       "        [15]], dtype=int32)>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding shuffling, prefetching, caching, multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "                lambda: map(tuple, json_generator(data_file)), \n",
    "                output_types=(tf.string,)*2)\\\n",
    "            .map(preprocess_function, num_parallel_calls=4)\\\n",
    "            .cache()\\\n",
    "            .shuffle(buffer_size=10000)\\\n",
    "            .padded_batch(4, padded_shapes=([None], [None], [1], [1]))\\\n",
    "            .prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(4, 16), dtype=int32, numpy=\n",
       " array([[   2,   18,  236,   60,  342,   54,  680,    5,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0],\n",
       "        [   2,   18,  857,  705,  121,   95,    4, 1616,  176, 2944,    7,\n",
       "            4,  978,  176,    5,    3],\n",
       "        [   2,    6,   50,  143,  521,  178,    4, 4536,  726,  490,    5,\n",
       "            3,    0,    0,    0,    0],\n",
       "        [   2,   46,  882,  218,   16,    7,    8, 1075,   13,    4, 1683,\n",
       "           53,  165,    5,    3,    0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 15), dtype=int32, numpy=\n",
       " array([[   2,   22,  198,   64, 2164,   37,  106,    4,    3,    0,    0,\n",
       "            0,    0,    0,    0],\n",
       "        [   2,   22,  807,  300,   96,   13, 1561,  819,    9,    7, 2086,\n",
       "          190,  179,    4,    3],\n",
       "        [   2,    5,   42,   71,  713,   51,   19, 6052,  676,    4,    3,\n",
       "            0,    0,    0,    0],\n",
       "        [   2,  124,  924, 1837,   21,  486,   45, 6622,   94, 2121,    4,\n",
       "            3,    0,    0,    0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       " array([[ 9],\n",
       "        [16],\n",
       "        [12],\n",
       "        [15]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(4, 1), dtype=int32, numpy=\n",
       " array([[ 9],\n",
       "        [15],\n",
       "        [11],\n",
       "        [12]], dtype=int32)>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adding steps to create batches of equal sizes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sort_batch(src, tgt, src_len, tgt_len):\n",
    "    \"\"\" Takes a large batch and sorts it descendingly according to the src length \"\"\"\n",
    "    sorting_order = tf.argsort(tf.squeeze(src_len, axis=-1), direction='DESCENDING')\n",
    "    src = tf.gather(src, sorting_order, axis=0)\n",
    "    tgt = tf.gather(tgt, sorting_order, axis=0)\n",
    "    src_len = tf.gather(src_len, sorting_order, axis=0)\n",
    "    return src, tgt, src_len, tgt_len\n",
    "\n",
    "def cut_length(src, tgt, src_len, tgt_len):\n",
    "    \"\"\" Cuts off padding fomr a padded sequence \"\"\"\n",
    "    src = src[:tf.squeeze(src_len)]\n",
    "    tgt = tgt[:tf.squeeze(tgt_len)]\n",
    "    return src, tgt, src_len, tgt_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = tf.data.Dataset.from_generator(\n",
    "                lambda: map(tuple, json_generator(data_file)), \n",
    "                output_types=(tf.string,)*2)\\\n",
    "            .map(preprocess_function, num_parallel_calls=4)\\\n",
    "            .cache()\\\n",
    "            .shuffle(buffer_size=10000)\\\n",
    "\n",
    "# Create buffer to be sorted and pad to max length\n",
    "dataset = dataset.padded_batch(10000, padded_shapes=([None], [None], [1], [1]))\n",
    "\n",
    "# Sort buffer by length\n",
    "dataset = dataset.map(\n",
    "    sort_batch,\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "# Resolve buffer and cut each element to its original length\n",
    "dataset = dataset.unbatch()\n",
    "dataset = dataset.map(\n",
    "    cut_length,\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "dataset = dataset\\\n",
    "            .padded_batch(batch_size, padded_shapes=([None], [None], [1], [1]))\\\n",
    "            .prefetch(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(16, 40), dtype=int32, numpy=\n",
       " array([[   2,    6,   10,    7,    4,  742,  308,   82,   76,   19,  596,\n",
       "          675,   19,  269,    4,  742, 3424,   43, 1371,   22,   15,   14,\n",
       "            4, 3425,    7,    8,  996,   15,   12,   90,  742, 3426,   12,\n",
       "          742,  954,    7,    8,  113,    5,    3],\n",
       "        [   2,   59,   27,  400,   16,   32,   92,   15,   14,    8,   30,\n",
       "         1929,   19, 1080,   66,   13,    8,  391,    7,    8,  168,   29,\n",
       "          335,   15,   12,    8,  194,   95,  140,  111,  326,  277,  100,\n",
       "            7, 2665,    5,    3,    0,    0,    0],\n",
       "        [   2,    6,   17,    7,    4,   53,   25,   12,  215, 1482,    9,\n",
       "            4, 1924,   14,  433,    7,  142,   15,   49,  606,  337,   49,\n",
       "           12,    4,   55,  543,   95,   49,   15,   73,  364, 2660,   75,\n",
       "         1925,    5,    3,    0,    0,    0,    0],\n",
       "        [   2,    6,  124,  154,    7,    4,   53,  308,   14,    4,   64,\n",
       "            7,   11,  159,   11,  208,  620,   54,   51,  108,   13,   33,\n",
       "         1937,   15,   29,   31,  786,  154,    7,   34,  719,   56,    8,\n",
       "           64,    5,    3,    0,    0,    0,    0],\n",
       "        [   2,    6,  213,    7,    4,   26,   25,   15,   12,   26,  148,\n",
       "           15,   99,    9,    8, 1078,   13,   31,  164,   15,   53, 2662,\n",
       "         2663,   15,   14,    4,   62, 1258, 1927,   32,    9,    8,   84,\n",
       "            5,    3,    0,    0,    0,    0,    0],\n",
       "        [   2,   18,  119,   16,   35,    7,    8,  221,   13,    8,   47,\n",
       "           15,    8,   66,   14,   26,  136,   11,   35,  237, 1571,   33,\n",
       "          159,  121,   29,    8,   90,    9,    7,  137,   11,   72, 1756,\n",
       "            5,    3,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,   14,  965, 3238,   96,   15,   21,    4,   34,\n",
       "         2198,   12,   36,  136,   14,  721,   25,   15,    9,   66,  867,\n",
       "           20,    8,   74,   15, 3239,    4,  174, 1111,   14,    4, 3240,\n",
       "            5,    3,    0,    0,    0,    0,    0],\n",
       "        [   2, 3776,   15,    7,    4,  735,   15,   66,   10,   11,  161,\n",
       "           12,   15,   20,    4, 2235,   94,   15,   79,  919,    9,    4,\n",
       "          368,   15,   29, 3777,    4,   10,   97,  629, 1363, 1048,    5,\n",
       "            3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6, 3204,   10,    7,   31,  103, 1121,   35,   76,   19,\n",
       "            4,   17,    7,  137,    9,    8, 1181,   14,    4,  353,  243,\n",
       "            9,  201,  171,    7,    8,  221,   13,    8, 1181,    5,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,   21,    4,   24,   25,   15,   26, 1471,   15,\n",
       "           12,   24, 1172,   15,    7,    4, 1341, 2084,  183,   15,  157,\n",
       "         4867,   61,    8,  134,   19, 1502,    9,   33,  460,    5,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,  130,   81,    7,    4,   26,  187,   15, 1248,  418,\n",
       "           15,   26,  568,   12,   26, 2420,   15,   44,   51,    4, 1092,\n",
       "         2153,   13,    4,  130, 1212,   57,   49,  606,    5,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2, 2351,    4, 3940,  222,   15,    4,   10,   11,   87,   89,\n",
       "            4,  261,   13,   45,  125,   11,    7,    4,   83,   13, 1202,\n",
       "           84,   15,   14, 1202,  278,    7,    8,  113,    5,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   27,   10, 1699,   54,    4, 3233, 1119,  696,   73,\n",
       "            4,   27,   30,  111,    9,   15,    4,  882,   43, 3234,   15,\n",
       "          651,   15,   12, 1079, 1700,    7,    8,  113,    5,    3,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2, 2293,  421,    9,    4,  205,   15,    4,   10,   21,    4,\n",
       "           36,   25,   15,  137,  148,   15,  529, 1422,   15,   12,  721,\n",
       "          388,   11,  581,   57,    4,  169, 1154,    5,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   10,   15,   81,   73,   31,  600,   15,  135,   79,\n",
       "           71,  224,   11, 1044,   81,   73,   31,  600,   12,   11, 2251,\n",
       "            4,  251,   13,  286,   19,    4, 2570,    5,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    6,   30,   21,    4,   36,  366,   12,   62,   25,  308,\n",
       "         1348,    4,   62, 1483,   29,    4,   30,    7,    4,   26,   12,\n",
       "           34,  366,  308,   12,   34,  226,  143,    5,    3,    0,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(16, 24), dtype=int32, numpy=\n",
       " array([[   2,    5,   12,    9, 4172,   30,   48,    7,   25,    6,   14,\n",
       "          163,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,   61,  118,  492,   50,  150,    6,  511,   18,  118,   20,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,   15,   20,    9,  249,   91,   10,  236,  483,   11,   13,\n",
       "          462,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,  493,    9,  249,  670,    8,    7,   99,    9,  184,\n",
       "          294,  130,   32,    7,  222, 2934, 2935,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   12,    9,    7,   84,   36,   10,   84,  109,    6,\n",
       "           14,   11,   27, 1450,   45,  522,    6,   94,    6, 2901,  404,\n",
       "          139,    6],\n",
       "        [   2,   22,   83,   59,  320,   11,   14,   43,    6,   14,    8,\n",
       "           84,  221,  109,   30,  547,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   12,    8, 3866,  148,   10,  284,  265,    6,   14,\n",
       "           18,  426, 2263,   10,  368,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2, 4773,    6,   21,  638,    6,  197,   16,   12,    6,   10,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5, 2236,   12,    9,  767,  788,    6,   14,   48,   13,\n",
       "          685,  641,   20,   11,   14, 1096,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   12,    9,  131,   36,    6,   85,  707,   10,   60,\n",
       "         1623,    9,    7,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,   15,  123,    8,  126, 2648,    6, 5868,    6,   84,  815,\n",
       "           10,   85,  666,   62,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   12,   68,  121,   37,  386,   45, 5067,   51,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   90,   12, 3858,   18, 3859,  114,    6,   41,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   12,  672,  734,    6,    8,   65,   36,    6,  268,\n",
       "          109,    6,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,  199,  982,  178,   12,   40,   18,  115,   52,    6,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0],\n",
       "        [   2,    5,   26,    8,   65,  208,   10,    7,  102,   91,  225,\n",
       "           19,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "            0,    0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(16, 1), dtype=int32, numpy=\n",
       " array([[40],\n",
       "        [37],\n",
       "        [36],\n",
       "        [36],\n",
       "        [35],\n",
       "        [35],\n",
       "        [35],\n",
       "        [34],\n",
       "        [33],\n",
       "        [33],\n",
       "        [32],\n",
       "        [32],\n",
       "        [32],\n",
       "        [31],\n",
       "        [31],\n",
       "        [31]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(16, 1), dtype=int32, numpy=\n",
       " array([[12],\n",
       "        [11],\n",
       "        [12],\n",
       "        [18],\n",
       "        [24],\n",
       "        [16],\n",
       "        [16],\n",
       "        [11],\n",
       "        [17],\n",
       "        [14],\n",
       "        [15],\n",
       "        [10],\n",
       "        [10],\n",
       "        [13],\n",
       "        [11],\n",
       "        [12]], dtype=int32)>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extended dataset from sharded CSVs with batch-length bucketing\n",
    "\n",
    "This dataloader loads directly from sharded csv files (these can also be passed as GCS bucket with `gs://` if the machine has the rights to read from the bucket). In addition, the dataset groups sequences of equal input-length together to minimize the number of padding-elements and computation on paddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pattern to find files. Tensorflow will automatically pick up all files that fit the pattern.\n",
    "file_pattern = 'data/csv/train_*.csv'\n",
    "\n",
    "batch_size = 8                    # Final batch size\n",
    "parallel_processes = 4            # Number of parallel workers\n",
    "shuffle_buffer_size = 10000       # Buffer size for shuffling\n",
    "length_sort_buffer_size = 10000   # Buffer size for sorting into equal length\n",
    "prefetch_length = 4               # Number of batches to pre-fetch\n",
    "skip_header_rows = 1              # Number of rows in files to skip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_csv(inp):\n",
    "    \"\"\" Splits the  \"\"\"\n",
    "    fields = tf.io.decode_csv(records=inp,\n",
    "                              record_defaults=[tf.constant([], dtype=tf.string)] * 2,\n",
    "                              field_delim=',')\n",
    "    return fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all the files that match the pattern\n",
    "dataset = tf.data.Dataset.list_files(file_pattern, seed=42)\n",
    "\n",
    "# Reading from csv and interleaving the files\n",
    "# You can even shuffle before this to read the files in random order for better shuffling\n",
    "dataset = dataset.interleave(\n",
    "    lambda fp: tf.data.TextLineDataset(fp).skip(skip_header_rows),\n",
    "    cycle_length=4,\n",
    "    num_parallel_calls=4)\n",
    "\n",
    "# Decode csv input\n",
    "dataset = dataset.map(decode_csv, num_parallel_calls=parallel_processes)\n",
    "\n",
    "# Same preprocessing as before\n",
    "dataset = dataset\\\n",
    "            .map(preprocess_function, num_parallel_calls=parallel_processes)\\\n",
    "            .shuffle(buffer_size=shuffle_buffer_size)\\\n",
    "\n",
    "# Create buffer to be sorted and pad to max length\n",
    "dataset = dataset.padded_batch(length_sort_buffer_size, \n",
    "                               padded_shapes=([None], [None], [1], [1]))\n",
    "\n",
    "# Sort buffer by length\n",
    "dataset = dataset.map(\n",
    "    sort_batch,\n",
    "    num_parallel_calls=parallel_processes)\n",
    "\n",
    "# Resolve buffer and cut each element to its original length\n",
    "dataset = dataset.unbatch()\n",
    "dataset = dataset.map(\n",
    "    cut_length,\n",
    "    num_parallel_calls=parallel_processes)\n",
    "\n",
    "# Batch to desired train-batch size and prefetch\n",
    "dataset = dataset\\\n",
    "            .padded_batch(batch_size, padded_shapes=([None], [None], [1], [1]))\\\n",
    "            .shuffle(shuffle_buffer_size // batch_size)\\\n",
    "            .prefetch(prefetch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Length of the sequences in batches:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch  0:   15  15  15  15  15  15  15  15\n",
      "Batch  1:   13  13  13  13  13  13  13  13\n",
      "Batch  2:   13  13  13  13  13  13  13  13\n",
      "Batch  3:   24  24  24  24  24  24  24  24\n",
      "Batch  4:   21  21  21  21  21  21  21  21\n",
      "Batch  5:   21  21  21  21  21  21  21  21\n",
      "Batch  6:   10  10  10  10  10  10  10  10\n",
      "Batch  7:   21  21  21  21  21  21  21  21\n",
      "Batch  8:   16  16  16  16  16  16  16  16\n",
      "Batch  9:   17  17  17  17  17  17  17  17\n",
      "Batch 10:   16  16  16  16  16  16  16  16\n",
      "Batch 11:   10  10  10  10  10  10  10  10\n",
      "Batch 12:    9   9   9   9   9   9   9   9\n",
      "Batch 13:    8   8   8   8   8   8   8   8\n",
      "Batch 14:   10  10  10  10  10  10  10  10\n",
      "Batch 15:   10  10  10  10  10  10  10  10\n",
      "Batch 16:   14  14  14  14  14  14  14  14\n",
      "Batch 17:   13  13  13  13  13  13  13  13\n",
      "Batch 18:   18  18  18  18  18  18  18  18\n",
      "Batch 19:   16  16  16  16  16  16  16  16\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    src, tgt, src_len, tgt_len = next(it)\n",
    "    print(\"Batch {: >2d}:   \".format(i) + \"  \".join([\"{: >2d}\".format(x[0]) for x in src_len.numpy()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(8, 15), dtype=int32, numpy=\n",
       " array([[   2,   18,   23,   16,  121,   12,   66,   13,  180,   11,  234,\n",
       "            4,  217,    5,    3],\n",
       "        [   2,    6,  544,   12, 1195,   35,    7,   41,   13,    4,  561,\n",
       "          246,  123,    5,    3],\n",
       "        [   2,   91,   32,    7,    4,  176,  161,   12,   66,   11,  177,\n",
       "            8,  286,    5,    3],\n",
       "        [   2,  281,   23,   15,   21,  181,   36,  259,   15, 1271,    4,\n",
       "         1429,  328,    5,    3],\n",
       "        [   2,   18,   23,  153,    7,   41,   13, 1004,   12,    4,   55,\n",
       "          181,  199,    5,    3],\n",
       "        [   2,    6, 1598,  797,  128,   33, 2902,    7,   41,   13,    4,\n",
       "           40,   13,   23,    3],\n",
       "        [   2,    6,   10,   12,    4,   17,  186,  502,   16,   44,   39,\n",
       "            8,  107,    5,    3],\n",
       "        [   2,    6,   55,   26,   12,   24,   22,   11,   72,   57,    4,\n",
       "          214,   83,    5,    3]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(8, 19), dtype=int32, numpy=\n",
       " array([[   2,   22,   49,  100,  112,    6,   10,   18,  297,  335,   16,\n",
       "          242,    4,    3,    0,    0,    0,    0,    0],\n",
       "        [   2,  357,   10, 1114,   59,   31,   13,   32, 1115, 1393,    0,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   78,    6,   17,   21,  190,   50,   10,  244,    6,   10,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,  252,   49,    8, 1078,  282,   17,   21,   86,   70, 1508,\n",
       "            4,    3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,   22,   49,   50,   31, 1299,   10,    7,   79,  433,  202,\n",
       "            4,    3,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5, 1268,  250,  154, 3331,   31,   13, 1544,    4,    3,\n",
       "            0,    0,    0,    0,    0,    0,    0,    0],\n",
       "        [   2,    5,   12,   10,   18,   20,    6,   17,   37,  170,   67,\n",
       "           77,   10, 1125,  188,    4,    3,    0,    0],\n",
       "        [   2,    5,  279,  103,   24,   89,   25,   71,   51,   18,  183,\n",
       "            4,    3,    0,    0,    0,    0,    0,    0]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
       " array([[15],\n",
       "        [15],\n",
       "        [15],\n",
       "        [15],\n",
       "        [15],\n",
       "        [15],\n",
       "        [15],\n",
       "        [15]], dtype=int32)>,\n",
       " <tf.Tensor: shape=(8, 1), dtype=int32, numpy=\n",
       " array([[18],\n",
       "        [10],\n",
       "        [11],\n",
       "        [14],\n",
       "        [13],\n",
       "        [18],\n",
       "        [19],\n",
       "        [15]], dtype=int32)>)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
